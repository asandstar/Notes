The process of learning **without training lables**, can also be called clustering or grouping. 

The most basic way to model the world: to assume that it’s made up of distinct groups of objects that share properties. 

Unsupervised clustering: Immediately recognizing different properties and creating categories. 

Without labels provided by a teacher,we do have a key assumption about **the world that we’re modeling**: 

certain objects are more similar to each other than others. 

K-means clustering: a simple algorithm.

NEED: a way to **compare** observations, 

a way to **guess** how many clusters exist in the data, 

a way to **calculate** averages for each cluster it predicts.

Model the world!

step1: **Predict**.

What does the model expect the world to look like? (which flowers should be clustered together because they’re the same species?)

step2: Correct or **Learn.** 

The model will update its belief to agree with its observation of the world. According to the result, repeat the process, stare with a new prediction step. 

And predict new labels using the Xs that mark the **averages** of each label. (很多x坐标)

Give every datapoint the label of its closest X—type1, type2, type3 , then calculate new **averages.**

Because we learned about the world from observation, so we makes this unsupervised learning, even though we relied a tiny bit on a teacher for confirmation and help. 

Somehow, we need the model to create a representation to tells us if two images are similar. 

Representation Learning:finding Meaningful Patterns across many images that are more abstract than individual pixels and.(HELP US UNDERSTAND WHAT’S IN THE IMAGES ADN HOW TO COMPARE THEM TO EACH OTHER.)

↑both in supervised and unsupervised learning models， so we can find patterns with or without labels.

For AI, making a reconstruction would mean ***producing all the right pixel values*** to make a reconstruction.

For images, we’d have to update the model’s internal representations based on its reconstructions.

Unsupervised learning + Representation learning→AI can compare images

eg.AUTOENCODER: it uses the same basic principles of weights and biases to process **inputs**, pass data into **hidden neuron layers**, and finally to a **prediction output layer**. 

HOW AI WILL FULFILL ITS GRAND AMBITIONS?

“Unsupervised learning is the ultimate answer.”无监督学习
