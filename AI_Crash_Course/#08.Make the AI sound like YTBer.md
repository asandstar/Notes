AI won’t really understand anything, but it did a really good job of finding and copying patterns.

When we teach any AI system to understand and produce language, we’re really asking it to find and copy patterns in some behavior.

STEP1:PREPROCESSING

a computer can only process data as numbers!

Split sentences into words, and convert words into numbers.

TOKENIZATION: the process of splitting a sentence into a list of lexical tokens. 

MORPHOLOGY: the way a word gets shape-shifted to match a tense, like you’d add an”ED” to make something past tense, or when you shorten or combine words to make them totes-amazeballs. 

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/14706c4a-0396-4e2e-a2ae-608ce162e347/Untitled.png)

STEMMING（词干提取）: a process that removes a lot of extra word endings, like ED, ING, or LY,etc.

